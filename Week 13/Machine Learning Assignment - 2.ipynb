{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
    "# Overfitting occurs when a model learns not only the underlying pattern but also the noise in the training data, leading to poor performance on unseen data. Consequences include high accuracy on training data but low accuracy on test data. \n",
    "# Mitigation techniques:\n",
    "# - Cross-validation\n",
    "# - Pruning in decision trees\n",
    "# - Using simpler models\n",
    "# - Regularization techniques (L1 and L2)\n",
    "# - Increasing training data\n",
    "\n",
    "# Underfitting occurs when a model is too simple to capture the underlying patterns in the data, resulting in poor performance on both training and test data.\n",
    "# Mitigation techniques:\n",
    "# - Using more complex models\n",
    "# - Adding more features\n",
    "# - Reducing regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2: How can we reduce overfitting? Explain in brief.\n",
    "# To reduce overfitting:\n",
    "# - Use cross-validation to evaluate performance.\n",
    "# - Apply regularization techniques like L1 (Lasso) and L2 (Ridge).\n",
    "# - Increase training data size.\n",
    "# - Simplify the model by reducing parameters.\n",
    "# - Use dropout layers in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "# Underfitting happens when a model is too simple to capture the patterns in data, leading to poor accuracy. \n",
    "# Scenarios where underfitting occurs:\n",
    "# - Linear regression applied to non-linear data.\n",
    "# - Using insufficient features in the dataset.\n",
    "# - Excessive regularization.\n",
    "# - Too few training epochs in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n",
    "# Bias refers to error due to overly simplistic assumptions in the model, leading to underfitting. Variance refers to error due to excessive sensitivity to training data, causing overfitting.\n",
    "# - High Bias: Poor performance on both training and test data.\n",
    "# - High Variance: Good performance on training data but poor performance on test data.\n",
    "# Tradeoff: A balance between bias and variance ensures optimal model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n",
    "# Methods for detection:\n",
    "# - Plot learning curves (training vs. validation loss).\n",
    "# - Evaluate performance metrics (accuracy, precision) on training and test datasets.\n",
    "# - Cross-validation scores.\n",
    "# Overfitting: High training accuracy but low test accuracy.\n",
    "# Underfitting: Low training and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?\n",
    "# - High Bias: Models make strong assumptions and fail to capture patterns. Example: Linear regression for complex datasets.\n",
    "# - High Variance: Models are sensitive to fluctuations in training data. Example: Decision trees without pruning.\n",
    "# - Differences: High bias leads to underfitting, and high variance leads to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
    "# Regularization is a technique to reduce overfitting by adding a penalty to the model's complexity.\n",
    "# Techniques:\n",
    "# - L1 Regularization (Lasso): Adds absolute values of coefficients to the loss function, resulting in sparse models.\n",
    "# - L2 Regularization (Ridge): Adds squared values of coefficients, preventing large weights.\n",
    "# - Dropout: Randomly drops connections in neural networks during training.\n",
    "# - Early Stopping: Stops training when validation performance stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
