{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate.\n",
    "# A1. Linear regression predicts continuous outcomes, while logistic regression predicts probabilities for categorical outcomes, typically binary. \n",
    "# For example, logistic regression is more appropriate for predicting whether a patient has a disease (yes/no) based on medical test results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the cost function used in logistic regression, and how is it optimized?\n",
    "# A2. Logistic regression uses the log-loss (binary cross-entropy) cost function:\n",
    "# Cost = -1/N * sum(y*log(p) + (1-y)*log(1-p)),\n",
    "# where y is the actual label, and p is the predicted probability. \n",
    "# The cost function is optimized using gradient descent or variants like stochastic gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting.\n",
    "# A3. Regularization adds a penalty term to the cost function to constrain model complexity:\n",
    "# - L1 regularization (Lasso) encourages sparsity by shrinking some coefficients to zero.\n",
    "# - L2 regularization (Ridge) shrinks coefficients uniformly.\n",
    "# Regularization prevents overfitting by discouraging overly complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression model?\n",
    "# A4. The ROC (Receiver Operating Characteristic) curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings. \n",
    "# The area under the curve (AUC) measures model performance:\n",
    "# - AUC = 1: Perfect model.\n",
    "# - AUC = 0.5: Random guessing.\n",
    "# Higher AUC values indicate better classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. What are some common techniques for feature selection in logistic regression? How do these techniques help improve the model's performance?\n",
    "# A5. Common feature selection techniques include:\n",
    "# - Recursive Feature Elimination (RFE): Iteratively removes least significant features.\n",
    "# - L1 regularization: Shrinks irrelevant coefficients to zero.\n",
    "# - Mutual Information: Measures dependency between features and the target.\n",
    "# These techniques improve performance by reducing overfitting and focusing on relevant predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing with class imbalance?\n",
    "# A6. Strategies include:\n",
    "# - Resampling: Oversample the minority class or undersample the majority class.\n",
    "# - Using class weights: Assign higher weights to the minority class in the cost function.\n",
    "# - Synthetic data generation: Use methods like SMOTE to generate synthetic samples for the minority class.\n",
    "# - Adjusting thresholds: Choose an optimal decision threshold based on precision-recall trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q7. Can you discuss some common issues and challenges that may arise when implementing logistic regression, and how they can be addressed? For example, what can be done if there is multicollinearity among the independent variables?\n",
    "# A7. Common issues:\n",
    "# - Multicollinearity: Address it by using regularization (L2 penalty) or removing correlated features.\n",
    "# - Imbalanced datasets: Use resampling techniques or adjust class weights.\n",
    "# - Overfitting: Apply regularization or reduce the number of features.\n",
    "# - Non-linearity: Logistic regression assumes a linear relationship between predictors and log-odds. Use feature engineering or switch to non-linear models for complex patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
