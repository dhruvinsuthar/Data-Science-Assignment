{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between Polynomial Functions and Kernel Functions in Machine Learning: Polynomial functions and kernel functions are related in that polynomial kernel functions are based on polynomial functions. A kernel function transforms the input data into a higher-dimensional space where a linear separation might be possible, even if the original data is not linearly separable. The polynomial kernel is a specific type of kernel function that uses a polynomial function to compute the similarity between data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Polynomial Kernel: 97.78%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "svm_poly = SVC(kernel='poly', degree=3, coef0=1)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "y_pred = svm_poly.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Polynomial Kernel: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of Increasing Epsilon on the Number of Support Vectors in SVR: In Support Vector Regression (SVR), epsilon defines the margin of tolerance, within which no penalty is given for errors. As increases, the model becomes more tolerant to errors, leading to fewer support vectors. This happens because more data points fall within the œµ-tube, meaning fewer data points contribute to the margin. When epsilon is small, the model is more sensitive and may create more support vectors to fit the data closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Function: The choice of kernel (linear, polynomial, RBF) impacts how data is transformed into a higher-dimensional space. Polynomial and RBF kernels are commonly used for non-linear relationships, while a linear kernel is used for simpler, linear relationships.\n",
    "\n",
    "C Parameter: Controls the trade-off between maximizing the margin and minimizing classification error. A high value of C emphasizes minimizing errors (overfitting), while a low C value allows for more margin violations but might generalize better.\n",
    "\n",
    "Epsilon (ùúñ): Defines the margin of tolerance where no penalty is assigned for errors. A higher epsilon results in fewer support vectors, as the model becomes more lenient in how it treats deviations from the true output. A small epsilon value results in a model that fits the data more closely.\n",
    "\n",
    "Gamma Parameter: In non-linear kernels, gamma controls how much influence each training point has. A high gamma makes the decision boundary very sensitive to individual points (risk of overfitting), while a low gamma leads to a smoother boundary (underfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      0.92      0.96        13\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.762 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.952 total time=   0.0s\n",
      "Best parameters from GridSearchCV: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['iris_svc_model.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'kernel': ['linear', 'rbf']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n",
    "\n",
    "best_svc = grid_search.best_estimator_\n",
    "X_scaled = scaler.fit_transform(X) \n",
    "best_svc.fit(X_scaled, y)\n",
    "\n",
    "joblib.dump(best_svc, 'iris_svc_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
